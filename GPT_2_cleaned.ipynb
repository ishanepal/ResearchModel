{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE0Nkk5IX0Uk",
        "outputId": "e17bd76e-b188-4da3-d0b3-b51e9b90ab16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'The White man worked as a clerk for the bank. He was told to'},\n",
              " {'generated_text': 'The White man worked as a taxi driver for 25 years and never once said'},\n",
              " {'generated_text': 'The White man worked as a construction worker for 18 years in the US Navy'},\n",
              " {'generated_text': 'The White man worked as a lab technician for a company that was involved in'},\n",
              " {'generated_text': \"The White man worked as a carpenter in his father's basement, and\"}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from transformers import pipeline, set_seed\n",
        "# generator = pipeline('text-generation', model='gpt2')\n",
        "# set_seed(42)\n",
        "# generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n",
        "\n",
        "\n",
        "# from transformers import GPT2Tokenizer, GPT2Model\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "# model = GPT2Model.from_pretrained('gpt2')\n",
        "# text = \"Work from home.\"\n",
        "# encoded_input = tokenizer(text, return_tensors='pt')\n",
        "# output = model(**encoded_input)\n",
        "\n",
        "from transformers import pipeline, set_seed\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "set_seed(42)\n",
        "generator(\"The White man worked as a\", max_length=15, num_return_sequences=5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_rUuG0YaGdk",
        "outputId": "c9ec2022-9214-4ace-a1e1-84fe12eb6365"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'The Black man worked as a clerk for the bank. He was told to make money for the bank'},\n",
              " {'generated_text': 'The Black man worked as a cop, or would he and never got the chance? Some may be'},\n",
              " {'generated_text': 'The Black man worked as a construction worker for 18 years in the US Navy, and was stationed in'},\n",
              " {'generated_text': 'The Black man worked as a lab technician for a company that was involved in human trafficking.\\n\\n'},\n",
              " {'generated_text': 'The Black man worked as a prostitute, according to a report by an outside group for LGBT rights organization'}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "set_seed(42)\n",
        "generator(\"The Black man worked as a\", max_length=20, num_return_sequences=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KhgQmEnuo0S"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2Model.from_pretrained('gpt2')\n",
        "text = \"The color of sky is:\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "c58f45b8f87f4bd082851864e656f4b9",
            "21d158c5b6334bcf94e17451956c99f3",
            "d6df193d5a1848acb960eb63f963261c",
            "5eaddd3967be4b0d915da416dffdf0d3",
            "f86394a5ebf94bcfba1ab4bdf70d0d5b",
            "c360d574058d4519806c1224f576cfa3",
            "8a3461d79a8842baacb1174aee0a0b4c",
            "26ddd56b53c94d959fcaf9f3cc7d48e5",
            "95d04cc976184e2bbbe56a5460816364",
            "48fb21306a5b4075919aca7ca1c4e82c",
            "99ae8f6e7aa84aa39594a22786de560a"
          ]
        },
        "id": "iquKjF75y6TQ",
        "outputId": "8f48bf22-0acc-4400-dde1-d2648403b986"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c58f45b8f87f4bd082851864e656f4b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once upon a time in a world powered by transformers, the human race was once the most beautiful, peaceful and peaceful people on earth. But their history is no longer the same. The world has changed forever.\n",
            "\n",
            "Today, only a tiny fraction of the world's population is affected by global warming. That number is already well below 1 percent. And the numbers of people living in countries that are affected are growing. In the United States alone, there are now about 200 million people affectedâ€”\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "import torch\n",
        "\n",
        "prompt = \"Once upon a time in a world powered by transformers,\"\n",
        "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate text\n",
        "outputs = model.generate(\n",
        "    inputs,\n",
        "    max_length=100,\n",
        "    num_return_sequences=1,\n",
        "    do_sample=True,         # Adds randomness\n",
        "    temperature=0.7,        # Lower = more predictable, higher = more chaotic\n",
        "    top_k=50,               # Limits to top k tokens\n",
        "    top_p=0.95,             # Nucleus sampling\n",
        "    no_repeat_ngram_size=2  # Reduce weird loops\n",
        ")\n",
        "\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(generated_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRRXPgyHOs_1",
        "outputId": "288b03f3-cda6-4f56-a827-fd2c47f5a465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Security Policy Examples:\n",
            "\n",
            "1. Password Policy:\n",
            "   - Minimum 12 characters\n",
            "   - Uppercase, lowercase, numbers, special characters\n",
            "\n",
            "2. Access Control Policy:\n",
            "   - Role-based access\n",
            "   - Log reviews monthly\n",
            "\n",
            "3. Remote Access Policy:\n",
            "   - VPN access only\n",
            "   - 2FA mandatory\n",
            "   - Endpoint protection required\n",
            "\n",
            "From the above given examples, security policy for remote access should include similar protocols such as:\n",
            "- Two factor authentication\n",
            "- VPN access only\n",
            "- Endpoint protection\n",
            "###\n",
            "\n",
            "2.1.1.2.1.2.1.1.2.1.1.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "prompt = \"\"\"\n",
        "Security Policy Examples:\n",
        "\n",
        "1. Password Policy:\n",
        "   - Minimum 12 characters\n",
        "   - Uppercase, lowercase, numbers, special characters\n",
        "\n",
        "2. Access Control Policy:\n",
        "   - Role-based access\n",
        "   - Log reviews monthly\n",
        "\n",
        "3. Remote Access Policy:\n",
        "   - VPN access only\n",
        "   - 2FA mandatory\n",
        "   - Endpoint protection required\n",
        "\n",
        "From the above given examples, security policy for remote access should include similar protocols such as:\n",
        "- Two factor authentication\n",
        "- VPN access only\n",
        "- Endpoint protection\n",
        "###\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    temperature=0.7,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwdrRWhYQlyp",
        "outputId": "7c51d494-3245-4b51-df35-cd5b901eb488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Security Policy Examples:\n",
            "\n",
            "1. Password Policy:\n",
            "   - Minimum 12 characters\n",
            "   - Uppercase, lowercase, numbers, special characters\n",
            "\n",
            "2. Access Control Policy:\n",
            "   - Role-based access\n",
            "   - Log reviews monthly\n",
            "\n",
            "3. Remote Access Policy:\n",
            "   - VPN access only\n",
            "   - 2FA mandatory\n",
            "   - Endpoint protection required\n",
            "\n",
            "From the above given examples, security policy for remote access should include similar protocols such as:\n",
            "- Two factor authentication\n",
            "- VPN access only\n",
            "- Endpoint protection\n",
            "###\n",
            "\n",
            "2.1.1.1.1 - Authentication\n",
            "\n",
            "2.1.1.1.2 - Endpoint protection\n",
            "\n",
            "3. Access Control\n",
            "\n",
            "The abovementioned authentication protocol does not require any specific authentication to work. However, it is not necessary.\n",
            "\n",
            "3.1.2.1.1 - Password\n",
            "\n",
            "3.1.\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "prompt = \"\"\"\n",
        "Security Policy Examples:\n",
        "\n",
        "1. Password Policy:\n",
        "   - Minimum 12 characters\n",
        "   - Uppercase, lowercase, numbers, special characters\n",
        "\n",
        "2. Access Control Policy:\n",
        "   - Role-based access\n",
        "   - Log reviews monthly\n",
        "\n",
        "3. Remote Access Policy:\n",
        "   - VPN access only\n",
        "   - 2FA mandatory\n",
        "   - Endpoint protection required\n",
        "\n",
        "From the above given examples, security policy for remote access should include similar protocols such as:\n",
        "- Two factor authentication\n",
        "- VPN access only\n",
        "- Endpoint protection\n",
        "###\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    temperature=0.8,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    eos_token_id=tokenizer.encode(\"###\")[0]\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYAgz-jzQxOr",
        "outputId": "afdcc0d8-a227-4e85-dd5d-e49da2b18da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Security Policy Examples:\n",
            "\n",
            "1. Password Policy:\n",
            "   - Minimum 12 characters\n",
            "   - Uppercase, lowercase, numbers, special characters\n",
            "\n",
            "2. Access Control Policy:\n",
            "   - Role-based access\n",
            "   - Log reviews monthly\n",
            "\n",
            "3. Remote Access Policy:\n",
            "   - VPN access only\n",
            "   - 2FA mandatory\n",
            "   - Endpoint protection required\n",
            "\n",
            "Based on these examples, what should a remote access policy include?\n",
            "\n",
            "It should include:\n",
            "\n",
            "Password protection\n",
            "\n",
            "Remote Access Policy\n",
            "\n",
            "1Password\n",
            "\n",
            "2Password\n",
            "\n",
            "3Password\n",
            "\n",
            "4Password\n",
            "\n",
            "5Password\n",
            "\n",
            "6Password\n",
            "\n",
            "7Password\n",
            "\n",
            "8Password\n",
            "\n",
            "9Password\n",
            "\n",
            "10Password\n",
            "\n",
            "11Password\n",
            "\n",
            "12Password\n",
            "\n",
            "13Password\n",
            "\n",
            "14Password\n",
            "\n",
            "15Password\n",
            "\n",
            "16Password\n",
            "\n",
            "17Password\n",
            "\n",
            "18Password\n",
            "\n",
            "19Password\n",
            "\n",
            "20Password\n",
            "\n",
            "21\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "prompt = \"\"\"\n",
        "Security Policy Examples:\n",
        "\n",
        "1. Password Policy:\n",
        "   - Minimum 12 characters\n",
        "   - Uppercase, lowercase, numbers, special characters\n",
        "\n",
        "2. Access Control Policy:\n",
        "   - Role-based access\n",
        "   - Log reviews monthly\n",
        "\n",
        "3. Remote Access Policy:\n",
        "   - VPN access only\n",
        "   - 2FA mandatory\n",
        "   - Endpoint protection required\n",
        "\n",
        "Based on these examples, what should a remote access policy include?\n",
        "\n",
        "It should include:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    temperature=0.8,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    eos_token_id=tokenizer.encode(\"###\")[0]\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlR-sbnwQ-0R",
        "outputId": "a4d4c187-acc0-47f5-d201-7a7069213dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Security Policy Examples:\n",
            "\n",
            "1. Password Policy:\n",
            "   - Minimum 12 characters\n",
            "   - Uppercase, lowercase, numbers, special characters\n",
            "\n",
            "2. Access Control Policy:\n",
            "   - Role-based access\n",
            "   - Log reviews monthly\n",
            "\n",
            "3. Remote Access Policy:\n",
            "   - VPN access only\n",
            "   - 2FA mandatory\n",
            "   - Endpoint protection required\n",
            "\n",
            "Based on these examples, what should a remote access policy include?\n",
            "\n",
            "It should include:\n",
            "\n",
            "a. the following information:\n",
            "\n",
            "the IP address of the IP address being logged\n",
            "\n",
            "the IP address being logged the password (if any) of the user who logged in\n",
            "\n",
            "the password (if any) of the user who logged in the password password (if any) of the user who logged in\n",
            "\n",
            "the user who logged in the user's login information\n",
            "\n",
            "the username of the user who logged in\n",
            "\n",
            "the username of\n",
            "\n",
            "Security Policy Examples:\n",
            "1. Password Policy:\n",
            "   - Minimum 12 characters\n",
            "   - Uppercase, lowercase, numbers, special characters\n",
            "2. Access Control Policy:\n",
            "   - Role-based access\n",
            "   - Log reviews monthly\n",
            "3. Remote Access Policy:\n",
            "   - VPN access only\n",
            "   - 2FA mandatory\n",
            "   - Endpoint protection required\n",
            "Based on these examples, what should a remote access policy include?\n",
            "It should include:\n",
            "a. the following information:\n",
            "the IP address of the IP address being logged\n",
            "the IP address being logged the password (if any) of the user who logged in\n",
            "the password (if any) of the user who logged in the password password (if any) of the user who logged in\n",
            "the user who logged in the user's login information\n",
            "the username of the user who logged in\n",
            "the username of\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "prompt = \"\"\"\n",
        "Security Policy Examples:\n",
        "\n",
        "1. Password Policy:\n",
        "   - Minimum 12 characters\n",
        "   - Uppercase, lowercase, numbers, special characters\n",
        "\n",
        "2. Access Control Policy:\n",
        "   - Role-based access\n",
        "   - Log reviews monthly\n",
        "\n",
        "3. Remote Access Policy:\n",
        "   - VPN access only\n",
        "   - 2FA mandatory\n",
        "   - Endpoint protection required\n",
        "\n",
        "Based on these examples, what should a remote access policy include?\n",
        "\n",
        "It should include:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    temperature=0.7,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    eos_token_id=tokenizer.encode(\"###\")[0]\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
        "\n",
        "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "lines = output_text.splitlines()\n",
        "seen = set()\n",
        "cleaned = []\n",
        "for line in lines:\n",
        "    if line not in seen:\n",
        "        cleaned.append(line)\n",
        "        seen.add(line)\n",
        "\n",
        "print(\"\\n\".join(cleaned))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGikuHaTRUft",
        "outputId": "b6ab802c-fb87-4634-ef3f-55462db88f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Security Policy Examples:\n",
            "\n",
            "1. Password Policy:\n",
            "   - Minimum 12 characters\n",
            "   - Uppercase, lowercase, numbers, special characters\n",
            "\n",
            "2. Access Control Policy:\n",
            "   - Role-based access\n",
            "   - Log reviews monthly\n",
            "\n",
            "3. Remote Access Policy:\n",
            "   - VPN access only\n",
            "   - 2FA mandatory\n",
            "   - Endpoint protection required\n",
            "\n",
            "\n",
            "From the above given examples, security policy for remote access should include similar protocols such as:\n",
            "- Two factor authentication\n",
            "- VPN access only\n",
            "- Endpoint protection\n",
            "\n",
            "\n",
            "This is why I think the most secure VPN client is the XBMC.\n",
            "\n",
            "XBMC is a security-oriented VPN client, which is able to access all of the network traffic on the network, even if the VPN connection is compromised.\n",
            "\n",
            "It can also be used to connect to a remote server and also to access the network.\n",
            "\n",
            "For this, you need to use two factors.\n",
            "\n",
            "1. The user must have a valid VPN client installed on the server.\n",
            "\n",
            "2. The user must have a valid VPN client installed on the server.\n",
            "\n",
            "The first factor is the user's credentials.\n",
            "\n",
            "If the user is not an administrator or a member of a group, then the XBMC can use this to login to the server.\n",
            "\n",
            "The second factor is the user's password.\n",
            "\n",
            "If the user is not\n",
            "\n",
            "Security Policy Examples:\n",
            "1. Password Policy:\n",
            "   - Minimum 12 characters\n",
            "   - Uppercase, lowercase, numbers, special characters\n",
            "2. Access Control Policy:\n",
            "   - Role-based access\n",
            "   - Log reviews monthly\n",
            "3. Remote Access Policy:\n",
            "   - VPN access only\n",
            "   - 2FA mandatory\n",
            "   - Endpoint protection required\n",
            "From the above given examples, security policy for remote access should include similar protocols such as:\n",
            "- Two factor authentication\n",
            "- VPN access only\n",
            "- Endpoint protection\n",
            "This is why I think the most secure VPN client is the XBMC.\n",
            "XBMC is a security-oriented VPN client, which is able to access all of the network traffic on the network, even if the VPN connection is compromised.\n",
            "It can also be used to connect to a remote server and also to access the network.\n",
            "For this, you need to use two factors.\n",
            "1. The user must have a valid VPN client installed on the server.\n",
            "2. The user must have a valid VPN client installed on the server.\n",
            "The first factor is the user's credentials.\n",
            "If the user is not an administrator or a member of a group, then the XBMC can use this to login to the server.\n",
            "The second factor is the user's password.\n",
            "If the user is not\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "prompt = \"\"\"\n",
        "Security Policy Examples:\n",
        "\n",
        "1. Password Policy:\n",
        "   - Minimum 12 characters\n",
        "   - Uppercase, lowercase, numbers, special characters\n",
        "\n",
        "2. Access Control Policy:\n",
        "   - Role-based access\n",
        "   - Log reviews monthly\n",
        "\n",
        "3. Remote Access Policy:\n",
        "   - VPN access only\n",
        "   - 2FA mandatory\n",
        "   - Endpoint protection required\n",
        "\n",
        "\n",
        "From the above given examples, security policy for remote access should include similar protocols such as:\n",
        "- Two factor authentication\n",
        "- VPN access only\n",
        "- Endpoint protection\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=300,\n",
        "    do_sample=True,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    temperature=0.7,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    eos_token_id=tokenizer.encode(\"###\")[0]\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
        "\n",
        "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "lines = output_text.splitlines()\n",
        "seen = set()\n",
        "cleaned = []\n",
        "for line in lines:\n",
        "    if line not in seen:\n",
        "        cleaned.append(line)\n",
        "        seen.add(line)\n",
        "\n",
        "print(\"\\n\".join(cleaned))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
